# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_TITLE=Content Jumpstart API
API_VERSION=1.0.0
DEBUG_MODE=True

# CORS
CORS_ORIGINS=http://localhost:5173,http://localhost:3000

# Database
DATABASE_URL=sqlite:///./data/operator.db

# JWT Authentication
# ============================================================================
# CRITICAL SECURITY: SECRET_KEY must be cryptographically random (32+ chars)
# ============================================================================
# Generate a secure key by running:
#   python -c "import secrets; print(secrets.token_urlsafe(32))"
#
# Example output: "xK9mP4vN2wQ7hR1tY8jL3nM6bV5cX0zA1sD4fG7hJ9kP2qW5eR8t"
#
# NEVER use default/example values in production!
# The application will FAIL to start if weak keys are detected.
# ============================================================================
SECRET_KEY=REPLACE_WITH_OUTPUT_FROM_COMMAND_ABOVE
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7

# Anthropic API
ANTHROPIC_API_KEY=sk-ant-your-key-here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Rate Limiting (70% of Anthropic limits)
RATE_LIMIT_REQUESTS_PER_MINUTE=2800
RATE_LIMIT_TOKENS_PER_MINUTE=280000

# Content Generation
PARALLEL_GENERATION=True
MAX_CONCURRENT_API_CALLS=5

# File Upload
MAX_UPLOAD_SIZE_MB=10
ALLOWED_BRIEF_EXTENSIONS=.txt,.md

# Paths
BRIEFS_DIR=../data/briefs
OUTPUTS_DIR=../data/outputs
LOGS_DIR=../logs

# Cache Configuration
# ============================================================================
# Query result caching tuned for production load (10 concurrent projects, 300 posts)
# Week 3 optimization: Increased 5x from initial development values
# ============================================================================

# Cache TTLs (Time To Live) in seconds
CACHE_TTL_SHORT=300    # 5 minutes - frequently changing data (projects list, posts list, runs)
CACHE_TTL_MEDIUM=600   # 10 minutes - semi-static data (individual projects, clients)
CACHE_TTL_LONG=3600    # 1 hour - static data (templates, system settings)

# Cache size limits (max entries per tier)
# Adjust based on your expected load:
# - Development: Use defaults (500/200/100)
# - Small production: 1000/500/200 for ~20 projects
# - Large production: 5000/2000/500 for ~100 projects
CACHE_MAX_SIZE_SHORT=500    # High volume, frequent access
CACHE_MAX_SIZE_MEDIUM=200   # Moderate volume, occasional changes
CACHE_MAX_SIZE_LONG=100     # Low volume, rare changes

# Celery Configuration (Phase 2 Optimization)
# ============================================================================
# Background job queue for long-running content generation tasks
# Prevents HTTP timeouts and enables progress tracking
# ============================================================================

# Redis broker and result backend
# Development: Use localhost
# Production: Use Redis cluster with persistence
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Task configuration
CELERY_TASK_TRACK_STARTED=True        # Track task start time
CELERY_TASK_SEND_SENT_EVENT=True      # Send task-sent events for monitoring
CELERY_TASK_TIME_LIMIT=600            # 10 minutes hard limit per task
CELERY_TASK_SOFT_TIME_LIMIT=540       # 9 minutes soft limit (allows cleanup)

# Redis connection settings
REDIS_URL=redis://localhost:6379/0
REDIS_MAX_CONNECTIONS=50
